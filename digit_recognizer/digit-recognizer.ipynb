{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-08T19:12:12.107999Z","iopub.execute_input":"2022-05-08T19:12:12.108522Z","iopub.status.idle":"2022-05-08T19:12:12.120539Z","shell.execute_reply.started":"2022-05-08T19:12:12.108471Z","shell.execute_reply":"2022-05-08T19:12:12.119658Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"## Other imports\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom sklearn.metrics import (\n  accuracy_score,\n  precision_score,\n  recall_score,\n  f1_score,\n  ConfusionMatrixDisplay,\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:12:12.301086Z","iopub.execute_input":"2022-05-08T19:12:12.301659Z","iopub.status.idle":"2022-05-08T19:12:12.307112Z","shell.execute_reply.started":"2022-05-08T19:12:12.301616Z","shell.execute_reply":"2022-05-08T19:12:12.306256Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"# Use GPU if available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Device is {device}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:12:12.453753Z","iopub.execute_input":"2022-05-08T19:12:12.454046Z","iopub.status.idle":"2022-05-08T19:12:12.459650Z","shell.execute_reply.started":"2022-05-08T19:12:12.454013Z","shell.execute_reply":"2022-05-08T19:12:12.458953Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"## Data loading\n\ndef load_data(path):\n    df = pd.read_csv(path)\n    X = df.drop(\"label\", axis=1).to_numpy()\n    Y = df[\"label\"].to_numpy()\n    return X, Y\n\n# Training data\nX, Y = load_data(\"/kaggle/input/digit-recognizer/train.csv\")\n\n# Test data\nX_test = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\").to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:12:12.619024Z","iopub.execute_input":"2022-05-08T19:12:12.619913Z","iopub.status.idle":"2022-05-08T19:12:19.123704Z","shell.execute_reply.started":"2022-05-08T19:12:12.619867Z","shell.execute_reply":"2022-05-08T19:12:19.122830Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"## Data exploration\n\n# Plot the number of samples per class\nlabels, counts = np.unique(Y, return_counts=True)\nplt.bar([str(label) for label in labels], counts)\nplt.xlabel(\"Class\")\nplt.ylabel(\"Number of samples\")\nplt.title(\"Number of samples per class\")\n\n# Plot one sample from each class\nfig = plt.figure(figsize=[20, 8])\nfor label in labels:\n    first_label_idx = np.where(Y == label)[0][0]\n    ax = fig.add_subplot(2 , 5, label+1)\n    ax.imshow(X[first_label_idx].reshape((28,28)), cmap=\"gray\")\n    ax.set_title(f\"Sample of class {label}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:12:19.125509Z","iopub.execute_input":"2022-05-08T19:12:19.125728Z","iopub.status.idle":"2022-05-08T19:12:20.705790Z","shell.execute_reply.started":"2022-05-08T19:12:19.125701Z","shell.execute_reply":"2022-05-08T19:12:20.704805Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"## Split training data into train and validation sets\n\ndef split_train_validation(data_length, percentage=0.8):\n    shuffled_indices = np.random.permutation(data_length)\n    n_train = round(data_length * percentage)\n    idxs_train = shuffled_indices[:n_train]\n    idxs_validation = shuffled_indices[n_train:]\n    return idxs_train, idxs_validation\n\nidxs_train, idxs_validation = split_train_validation(len(Y))\nX_train, Y_train = X[idxs_train], Y[idxs_train]\nX_validation, Y_validation = X[idxs_validation], Y[idxs_validation]","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:12:20.707027Z","iopub.execute_input":"2022-05-08T19:12:20.707280Z","iopub.status.idle":"2022-05-08T19:12:21.811059Z","shell.execute_reply.started":"2022-05-08T19:12:20.707250Z","shell.execute_reply":"2022-05-08T19:12:21.809889Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"## Create PyTorch datasets\n\nclass DigitDataset(Dataset):\n    def __init__(self, X, Y, transform=None):\n        self.X = X\n        self.Y = Y\n        self.transform = transform\n    \n    def __getitem__(self, idx):\n        x = self.X[idx].reshape(28,28)\n        y = self.Y[idx]\n        \n        if self.transform:\n            x = Image.fromarray(x.astype(np.uint8))\n            x = self.transform(x)\n        \n        return x, y\n    \n    def __len__(self):\n        return len(self.X)\n\ntransform = transforms.ToTensor()\ntrain_dataset = DigitDataset(X_train, Y_train, transform)\nvalidation_dataset = DigitDataset(X_validation, Y_validation, transform)\ncombined_dataset = DigitDataset(X, Y, transform)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:14:05.567943Z","iopub.execute_input":"2022-05-08T19:14:05.568237Z","iopub.status.idle":"2022-05-08T19:14:05.577423Z","shell.execute_reply.started":"2022-05-08T19:14:05.568201Z","shell.execute_reply":"2022-05-08T19:14:05.576511Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"## LeNet inspired network\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.feature_extraction_layers = nn.Sequential( # Input dim = (batch_size, 1, 28, 28)\n            nn.Conv2d(1, 6, kernel_size=5), # Output dim = (batch_size, 6, 24, 24)\n            nn.BatchNorm2d(6),\n            nn.ReLU(),\n            nn.MaxPool2d(2), # Output dim = (batch_size, 6, 12, 12)\n            nn.Conv2d(6, 16, kernel_size=5), # Output dim = (batch_size, 16, 8, 8)\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n        )\n        \n        self.classification_layer = nn.Sequential(\n            nn.Linear(1024, 600),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(600, 100),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(100, 10),\n            nn.Softmax(dim=1),\n        )\n        \n    def forward(self, x):\n        x = self.feature_extraction_layers(x)\n        x = torch.flatten(x, 1)\n        x = self.classification_layer(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:12:21.836967Z","iopub.execute_input":"2022-05-08T19:12:21.838132Z","iopub.status.idle":"2022-05-08T19:12:21.853335Z","shell.execute_reply.started":"2022-05-08T19:12:21.838084Z","shell.execute_reply":"2022-05-08T19:12:21.852274Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"## Network training\n\ndef train_model(model, criterion, optimizer, batch_size, dataset):\n    dataloader = DataLoader(dataset=train_dataset, batch_size=train_batch_size)\n    \n    for epoch in tqdm(range(epochs)):\n        model.train()\n        loss_curve = []\n\n        for X, Y in dataloader:\n            optimizer.zero_grad()\n\n            X = X.to(device)\n            Y = Y.to(device)\n\n            # Forward pass\n            Y_predicted = model(X)\n            loss = criterion(Y_predicted, Y)\n            loss_curve += [loss.item()]\n\n            # Backward pass\n            loss.backward()\n            optimizer.step()\n\n        print(f\"--- Iteration {epoch+1}: training loss = {np.array(loss_curve).mean():.4f} ---\")\n\n# Define the parameters\nmodel = Net().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\ntrain_batch_size = 100\nepochs = 20\n\ntrain_model(model, criterion, optimizer, train_batch_size, train_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:14:10.575824Z","iopub.execute_input":"2022-05-08T20:14:10.576107Z","iopub.status.idle":"2022-05-08T20:18:24.389102Z","shell.execute_reply.started":"2022-05-08T20:14:10.576068Z","shell.execute_reply":"2022-05-08T20:18:24.388446Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"## Deploy model on validation set\n\nvalidation_dataloader = DataLoader(dataset=validation_dataset)\n\npredicted = []\nactual = []\nwith torch.no_grad():\n    model.eval()\n    \n    for x, y in tqdm(validation_dataloader):\n        x = x.to(device)\n        y = y.detach().numpy()\n        \n        label_probabilities = model(x).cpu().detach().numpy()\n        label_predicted = np.argmax(label_probabilities)\n        \n        predicted.append(label_predicted)\n        actual.append(y)\n\npredicted = np.array(predicted)\nactual = np.array(actual)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:18:38.867844Z","iopub.execute_input":"2022-05-08T20:18:38.868297Z","iopub.status.idle":"2022-05-08T20:18:46.790878Z","shell.execute_reply.started":"2022-05-08T20:18:38.868260Z","shell.execute_reply":"2022-05-08T20:18:46.789854Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"## Evaluate on evaluation set\n\n# Compute performance metrics\nprint(f\"Accuracy: { accuracy_score(actual, predicted)}\")\nprint(f\"Precision scores (index corresponds to class): {precision_score(actual, predicted, average=None)}\")\nprint(f\"Recall scores (index corresponds to class): {recall_score(actual, predicted, average=None)}\")\nprint(f\"F1 scores (index corresponds to class): {f1_score(actual, predicted, average=None)}\")\n\n# Visualize the confusion matrix\ncmp = ConfusionMatrixDisplay.from_predictions(actual, predicted)\n_, ax = plt.subplots(figsize=(10,10))\ncmp.plot(ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:20:11.975979Z","iopub.execute_input":"2022-05-08T20:20:11.976290Z","iopub.status.idle":"2022-05-08T20:20:13.362519Z","shell.execute_reply.started":"2022-05-08T20:20:11.976257Z","shell.execute_reply":"2022-05-08T20:20:13.361609Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"## Train on combined training and validation data + deploy on test data\n\ntrain_model(model, criterion, optimizer, train_batch_size, combined_dataset)\n\n# Deploy on test data\npredicted = []\nwith torch.no_grad():\n    model.eval()\n    \n    for x in tqdm(X_test):\n        x = x.reshape(28,28)\n        x = Image.fromarray(x.astype(np.uint8))\n        x = transform(x).unsqueeze(0).to(device)\n        \n        label_probabilities = model(x).cpu().detach().numpy()\n        label_predicted = np.argmax(label_probabilities)\n        \n        predicted.append(label_predicted)\n\n# Save test predictions for submission\nlabels = pd.Series(predicted, name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,len(X_test)+1), name=\"ImageId\"), labels], axis=1)\nsubmission.to_csv(\"digit_recognizer_submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:20:17.015751Z","iopub.execute_input":"2022-05-08T20:20:17.016605Z","iopub.status.idle":"2022-05-08T20:25:31.428194Z","shell.execute_reply.started":"2022-05-08T20:20:17.016560Z","shell.execute_reply":"2022-05-08T20:25:31.427191Z"},"trusted":true},"execution_count":143,"outputs":[]}]}